{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "JGJmy4WfF2Gv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eFy1CA4h0_D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "Xsz0LVrxF4di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CTDataset(Dataset):\n",
        "    def __init__(self, filepath):\n",
        "        self.x, self.y = torch.load(filepath)\n",
        "        self.x = self.x / 255.\n",
        "        self.y = nn.functional.one_hot(self.y, num_classes=10).to(float)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "    def __getitem__(self, ix):\n",
        "        return self.x[ix], self.y[ix]"
      ],
      "metadata": {
        "id": "bkdItIMiiCz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "train_ds = CTDataset('./MNIST/training.pt')\n",
        "test_ds = CTDataset('./MNIST/test.pt')"
      ],
      "metadata": {
        "id": "dN6t_BjqiccL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_sampler = RandomSampler(train_ds, num_samples=10_000)"
      ],
      "metadata": {
        "id": "x82KnJCjrV_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, sampler=random_sampler)"
      ],
      "metadata": {
        "id": "IpE8pgZtit4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.Matrix1 = nn.Linear(28**2,100)\n",
        "        self.Matrix2 = nn.Linear(100,50)\n",
        "        self.Matrix3 = nn.Linear(50,10)\n",
        "        self.R = nn.ReLU()\n",
        "    def forward(self,x):\n",
        "        x = x.view(-1,28**2)\n",
        "        x = self.R(self.Matrix1(x))\n",
        "        x = self.R(self.Matrix2(x))\n",
        "        x = self.Matrix3(x)\n",
        "        return x.squeeze()"
      ],
      "metadata": {
        "id": "tVS33q2Cizbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyNeuralNet()"
      ],
      "metadata": {
        "id": "ejbcoQ0Ai0bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "BlVLkPiqFzFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(dataloader, model, loss, optimizer, n_epochs=20):\n",
        "    model.train()\n",
        "    # Optimization\n",
        "    opt = SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    # Train model\n",
        "    losses = []\n",
        "    epochs = []\n",
        "\n",
        "    N = len(dataloader)\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        for i, (x, y) in enumerate(dataloader):\n",
        "            # Update the weights of the network\n",
        "            optimizer.zero_grad()\n",
        "            loss_value = loss(model(x), y)\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            # Store training data\n",
        "            epochs.append(epoch+i/N)\n",
        "            losses.append(loss_value.item())\n",
        "\n",
        "        print(f'Epoch {epoch}/{n_epochs} Completed')\n",
        "\n",
        "    model.eval()\n",
        "    return np.array(epochs), np.array(losses)"
      ],
      "metadata": {
        "id": "IihBqwgWi2Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim_class = torch.optim\n",
        "optim_children = dir(optim_class)\n",
        "no_of_optimizers = [o.startswith(\"_\") for o in optim_children].index(True)\n",
        "optimizers = optim_children[:no_of_optimizers]\n",
        "optimizers = [o for o in optimizers if o!= \"Optimizer\"]\n",
        "\n",
        "for optimizer in optimizers:\n",
        "  print(getattr(optim_class, optimizer)(model.parameters(), lr=0.01))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3KjIGK-vui4",
        "outputId": "8f0377b2-7c7d-4145-f46e-0710bcb24631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASGD (\n",
            "Parameter Group 0\n",
            "    alpha: 0.75\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    lambd: 0.0001\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    t0: 1000000.0\n",
            "    weight_decay: 0\n",
            ")\n",
            "Adadelta (\n",
            "Parameter Group 0\n",
            "    differentiable: False\n",
            "    eps: 1e-06\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    rho: 0.9\n",
            "    weight_decay: 0\n",
            ")\n",
            "Adagrad (\n",
            "Parameter Group 0\n",
            "    differentiable: False\n",
            "    eps: 1e-10\n",
            "    foreach: None\n",
            "    initial_accumulator_value: 0\n",
            "    lr: 0.01\n",
            "    lr_decay: 0\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    weight_decay: 0.01\n",
            ")\n",
            "Adamax (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "LBFGS (\n",
            "Parameter Group 0\n",
            "    history_size: 100\n",
            "    line_search_fn: None\n",
            "    lr: 0.01\n",
            "    max_eval: 25\n",
            "    max_iter: 20\n",
            "    tolerance_change: 1e-09\n",
            "    tolerance_grad: 1e-07\n",
            ")\n",
            "NAdam (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    momentum_decay: 0.004\n",
            "    weight_decay: 0\n",
            ")\n",
            "RAdam (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    weight_decay: 0\n",
            ")\n",
            "RMSprop (\n",
            "Parameter Group 0\n",
            "    alpha: 0.99\n",
            "    centered: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    weight_decay: 0\n",
            ")\n",
            "Rprop (\n",
            "Parameter Group 0\n",
            "    differentiable: False\n",
            "    etas: (0.5, 1.2)\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    step_sizes: (1e-06, 50)\n",
            ")\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "SparseAdam (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is our project\n",
        "optimizer = SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "5TfbZV-3vyT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "n_epochs = 20"
      ],
      "metadata": {
        "id": "lviatQ8QjDV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_data, loss_data = train_model(train_dl, model, loss, optimizer, n_epochs)"
      ],
      "metadata": {
        "id": "j2A-uSGajLO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average the loss across all the data per epoch to get the total loss\n",
        "epoch_data_avgd = epoch_data.reshape(n_epochs,-1).mean(axis=1)\n",
        "loss_data_avgd = loss_data.reshape(n_epochs,-1).mean(axis=1)"
      ],
      "metadata": {
        "id": "XO2XDnVgjm4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.line(\n",
        "    x = epoch_data_avgd,\n",
        "    y = loss_data_avgd,\n",
        "    title = \"Cross Entropy (avgd per epoch)\",\n",
        "    range_x = [epoch_data_avgd.min(), epoch_data_avgd.max()],\n",
        "    range_y = [0, loss_data_avgd.max()*1.1],\n",
        "    markers=True,\n",
        "    labels = {\n",
        "        \"x\": \"Epoch\",\n",
        "        \"y\": \"Loss\"\n",
        "    }\n",
        ")\n",
        "#fig.update_traces(patch={\"line\": {\"dash\": \"dot\"}})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "w1oYUM9rrzTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "9dIVM6tEFwdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_count = 10"
      ],
      "metadata": {
        "id": "QaSyIeGHmpcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys = test_ds[:test_count] # test\n",
        "yhats = model(xs).argmax(axis=1)"
      ],
      "metadata": {
        "id": "OYITdVhgmaZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = 4\n",
        "rows = np.ceil(test_count/cols).astype(int)\n",
        "\n",
        "fig, ax = plt.subplots(rows, cols,figsize=(10,5))\n",
        "for i in range(test_count):\n",
        "    plt.subplot(rows, cols, i+1)\n",
        "    plt.imshow(xs[i])\n",
        "    plt.title(f'Predicted Digit: {yhats[i]}')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4kJYGjXymWxQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}